{"version":3,"sources":["../src/max-ten.js"],"names":[],"mappings":";AACA,YAAY,CAAC;;;;;;;;;kCACY,sBAAsB;;yBACpB,WAAW;;gCACX,mBAAmB;;;;gCAC3B,mBAAmB;;;;AACtC,IAAM,cAAc,GAAG;AACnB,OAAG,EAAE,CAAC;AACN,UAAM,EAAE,KAAK;CAChB,CAAC;;AAEF,SAAS,kBAAkB,CAAC,KAIvB,EAAE;QAHH,MAAM,GADkB,KAIvB,CAHD,MAAM;QACN,KAAK,GAFmB,KAIvB,CAFD,KAAK;QACL,KAAK,GAHmB,KAIvB,CADD,KAAK;;AAEL,QAAI,MAAM,KAAK,SAAS,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,SAAS,EAAE;AACpE,eAAO,KAAK,CAAC;KAChB;AACD,WAAO,MAAM,CAAC,GAAG,KAAK,IAAI,IAAI,KAAK,CAAC,GAAG,KAAK,IAAI,CAAC;CACpD;;;;;;;;AAQD,SAAS,YAAY,CAAC,IAAI,EAAE,QAAQ,EAAE;AAClC,WAAO;AACH,YAAI,EAAE,IAAI,CAAC,IAAI,GAAG,QAAQ,CAAC,IAAI,GAAG,CAAC;AACnC,cAAM,EAAE,QAAQ,CAAC,IAAI,IAAI,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,QAAQ,CAAC,MAAM;UAC7B,QAAQ,CAAC,MAAM;KAC/C,CAAC;CACL;;;;;;qBAKc,UAAU,OAAO,EAAgB;QAAd,OAAO,yDAAG,EAAE;;AAC1C,QAAM,MAAM,GAAG,OAAO,CAAC,GAAG,IAAI,cAAc,CAAC,GAAG,CAAC;AACjD,QAAM,QAAQ,GAAG,OAAO,CAAC,MAAM,IAAI,cAAc,CAAC,MAAM,CAAC;AACzD,QAAI,MAAM,GAAG,mCAAe,OAAO,CAAC,CAAC;QAChC,MAAM,GAAkC,OAAO,CAA/C,MAAM;QAAE,SAAS,GAAuB,OAAO,CAAvC,SAAS;QAAE,MAAM,GAAe,OAAO,CAA5B,MAAM;QAAE,SAAS,GAAI,OAAO,CAApB,SAAS;;AACzC,+BACK,MAAM,CAAC,SAAS,EAAC,UAAC,IAAI,EAAC;AACpB,YAAI,MAAM,CAAC,WAAW,CAAC,IAAI,EAAE,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,EAAE;AAC/C,mBAAO;SACV;AACD,YAAI,SAAS,GAAG,mCAAe,SAAS,CAAC,IAAI,CAAC,EAAE;AAC5C,sBAAU,EAAE,WAAW;AACvB,6BAAiB,EAAE,MAAM;SAC5B,CAAC,CAAC;;;;;;;;;;;;;AAaH,eAAO,8BAAc,CAAC,IAAI,CAAC,UAAA,SAAS,EAAI;AACpC,qBAAS,CAAC,OAAO,CAAC,UAAA,QAAQ,EAAI;AAC1B,oBAAI,IAAI,GAAG,QAAQ,CAAC,KAAK,CAAC;AAC1B,oBAAI,MAAM,GAAG,kCAAW,IAAI,CAAC,CAAC;AAC9B,oBAAI,eAAe,GAAG,CAAC,CAAC;AACxB,oBAAI,MAAM,GAAG,SAAS,CAAC,mBAAmB,CAAC,IAAI,CAAC,CAAC;AACjD,oBAAI,SAAS,GAAG,IAAI,CAAC;AACrB,sBAAM,CAAC,OAAO,CAAC,UAAC,KAAK,EAAE,KAAK,EAAK;AAC7B,wBAAI,OAAO,GAAG,KAAK,CAAC,YAAY,CAAC;AACjC,wBAAI,OAAO,KAAK,GAAG,EAAE;;AAEjB,4BAAI,YAAY,GAAG,kBAAkB,CAAC;AAClC,kCAAM,EAAE,MAAM,CAAC,KAAK,GAAG,CAAC,CAAC;AACzB,iCAAK,EAAE,KAAK;AACZ,iCAAK,EAAE,MAAM,CAAC,KAAK,GAAG,CAAC,CAAC;yBAC3B,CAAC,CAAC;;AAEH,4BAAI,CAAC,QAAQ,IAAI,YAAY,EAAE;AAC3B,mCAAO;yBACV;AACD,uCAAe,EAAE,CAAC;AAClB,iCAAS,GAAG,KAAK,CAAC;qBACrB;AACD,wBAAI,OAAO,KAAK,GAAG,EAAE;;AAEjB,uCAAe,GAAG,CAAC,CAAC;qBACvB;;AAED,wBAAI,eAAe,IAAI,MAAM,EAAE;AAC3B,4BAAI,kBAAkB,GAAG,MAAM,CAAC,eAAe,CAAC,SAAS,CAAC,aAAa,GAAG,CAAC,CAAC,CAAC;AAC7E,4BAAI,cAAc,GAAG,YAAY,CAAC,QAAQ,CAAC,GAAG,CAAC,KAAK,EAAE,kBAAkB,CAAC,CAAC;AAC1E,4BAAI,SAAS,GAAG,IAAI,OAAO,CAAC,SAAS,iBAAa,MAAM,iBAAc;AAClE,gCAAI,EAAE,cAAc,CAAC,IAAI,GAAG,CAAC;AAC7B,kCAAM,EAAE,cAAc,CAAC,MAAM;yBAChC,CAAC,CAAC;AACH,8BAAM,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;AACxB,uCAAe,GAAG,CAAC,CAAC;qBACvB;iBACJ,CAAC,CAAC;aACN,CAAC,CAAC;SACN,CAAC,CAAC;KACN,EACJ;CACJ","file":"max-ten.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport {RuleHelper} from \"textlint-rule-helper\"\nimport {getTokenizer} from \"kuromojin\";\nimport splitSentences from \"sentence-splitter\";\nimport Source from \"structured-source\";\nconst defaultOptions = {\n    max: 3, // 1文に利用できる最大の、の数\n    strict: false // 例外ルールを適応するかどうか\n};\n\nfunction isSandwichedMeishi({\n    before,\n    token,\n    after\n    }) {\n    if (before === undefined || after === undefined || token === undefined) {\n        return false;\n    }\n    return before.pos === \"名詞\" && after.pos === \"名詞\";\n}\n/**\n * add two positions.\n * note: line starts with 1, column starts with 0.\n * @param {Position} base\n * @param {Position} relative\n * @return {Position}\n */\nfunction addPositions(base, relative) {\n    return {\n        line: base.line + relative.line - 1, // line 1 + line 1 should be line 1\n        column: relative.line == 1 ? base.column + relative.column // when the same line\n                                   : relative.column               // when another line\n    };\n}\n/**\n * @param {RuleContext} context\n * @param {object} options\n */\nexport default function (context, options = {}) {\n    const maxLen = options.max || defaultOptions.max;\n    const isStrict = options.strict || defaultOptions.strict;\n    let helper = new RuleHelper(context);\n    let {Syntax, RuleError, report, getSource} = context;\n    return {\n        [Syntax.Paragraph](node){\n            if (helper.isChildNode(node, [Syntax.BlockQuote])) {\n                return;\n            }\n            let sentences = splitSentences(getSource(node), {\n                charRegExp: /[。\\?\\!？！]/,\n                newLineCharacters: \"\\n\\n\"\n            });\n            /*\n            <p>\n            <str><code><img><str>\n            <str>\n            </p>\n             */\n            /*\n            # workflow\n            1. split text to sentences\n            2. sentence to tokens\n            3. check tokens\n             */\n            return getTokenizer().then(tokenizer => {\n                sentences.forEach(sentence => {\n                    let text = sentence.value;\n                    let source = new Source(text);\n                    let currentTenCount = 0;\n                    let tokens = tokenizer.tokenizeForSentence(text);\n                    let lastToken = null;\n                    tokens.forEach((token, index) => {\n                        let surface = token.surface_form;\n                        if (surface === \"、\") {\n                            // 名詞に過去まわれている場合は例外とする\n                            let isSandwiched = isSandwichedMeishi({\n                                before: tokens[index - 1],\n                                token: token,\n                                after: tokens[index + 1]\n                            });\n                            // strictなら例外を例外としない\n                            if (!isStrict && isSandwiched) {\n                                return;\n                            }\n                            currentTenCount++;\n                            lastToken = token;\n                        }\n                        if (surface === \"。\") {\n                            // reset\n                            currentTenCount = 0;\n                        }\n                        // report\n                        if (currentTenCount >= maxLen) {\n                            let positionInSentence = source.indexToPosition(lastToken.word_position - 1);\n                            let positionInNode = addPositions(sentence.loc.start, positionInSentence);\n                            let ruleError = new context.RuleError(`一つの文で\"、\"を${maxLen}つ以上使用しています`, {\n                                line: positionInNode.line - 1,\n                                column: positionInNode.column\n                            });\n                            report(node, ruleError);\n                            currentTenCount = 0;\n                        }\n                    });\n                });\n            });\n        }\n    }\n}"]}